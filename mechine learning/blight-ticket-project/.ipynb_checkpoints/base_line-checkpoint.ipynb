{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe01d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352782bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (11,12,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Read data files\n",
    "train_df = pd.read_csv(\"train.csv\", encoding = \"latin1\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only common columns from both train and test df\n",
    "common_col = list(set(train_df.columns).intersection(set(test_df.columns)))\n",
    "common_col.append('compliance')\n",
    "train_df = train_df[common_col] # We have 28 cols for train and 27 cols for test\n",
    "train_df = train_df[train_df['compliance'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0df028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only USA country\n",
    "train_df = train_df[train_df['country'] == 'USA']\n",
    "test_df = test_df[test_df['country'] == 'USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e8671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "drop_col = ['ticket_id', 'admin_fee', 'state_fee', 'violation_zip_code', \n",
    "            'mailing_address_str_number', 'mailing_address_str_name', 'inspector_name',\n",
    "           'zip_code', 'violation_code', 'violator_name', 'violation_street_name', 'violation_street_number', 'city',\n",
    "           'violation_description', 'grafitti_status', 'non_us_str_code', 'judgment_amount',\n",
    "            'country', 'ticket_issued_date', 'hearing_date', 'disposition', 'clean_up_cost']\n",
    "train_df = train_df.drop(drop_col, axis = 1)\n",
    "test_id = test_df['ticket_id']\n",
    "test_df = test_df.drop(drop_col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c0374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine data types\n",
    "train_df['discount_amount'] = train_df['discount_amount'].astype(float)\n",
    "train_df['fine_amount'] = train_df['fine_amount'].astype(float)\n",
    "train_df['late_fee'] = train_df['late_fee'].astype(float)\n",
    "train_df['compliance'] = train_df['compliance'].astype(int)\n",
    "train_df['agency_name'] = train_df['agency_name'].astype('category')\n",
    "\n",
    "test_df['discount_amount'] = test_df['discount_amount'].astype(float)\n",
    "test_df['fine_amount'] = test_df['fine_amount'].astype(float)\n",
    "test_df['late_fee'] = test_df['late_fee'].astype(float)\n",
    "test_df['agency_name'] = test_df['agency_name'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51244ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode agency names\n",
    "le = LabelEncoder().fit(train_df['agency_name'])\n",
    "train_transformed = le.transform(train_df['agency_name'])\n",
    "test_transformed = le.transform(test_df['agency_name'])\n",
    "\n",
    "ohe = OneHotEncoder().fit(np.array(train_transformed).reshape(-1, 1))\n",
    "train_ohe = ohe.transform(np.array(train_transformed).reshape(-1, 1))\n",
    "test_ohe = ohe.transform(np.array(test_transformed).reshape(-1, 1))\n",
    "train_ohe_df = pd.DataFrame(train_ohe.toarray())\n",
    "test_ohe_df = pd.DataFrame(test_ohe.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef726da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode states\n",
    "train_df['state'].fillna('N/A', inplace = True)\n",
    "test_df['state'].fillna('N/A', inplace = True)\n",
    "le2 = LabelEncoder().fit(train_df['state'])\n",
    "train_transformed2 = le2.transform(train_df['state'])\n",
    "test_transformed2 = le2.transform(test_df['state'])\n",
    "\n",
    "ohe2 = OneHotEncoder().fit(np.array(train_transformed2).reshape(-1, 1))\n",
    "train_ohe2 = ohe2.transform(np.array(train_transformed2).reshape(-1, 1))\n",
    "test_ohe2 = ohe2.transform(np.array(test_transformed2).reshape(-1, 1))\n",
    "train_ohe_df2 = pd.DataFrame(train_ohe2.toarray())\n",
    "test_ohe_df2 = pd.DataFrame(test_ohe2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d46633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "train_df_cleaned = pd.concat([train_df, train_ohe_df, train_ohe_df2], axis = 1)\n",
    "test_df_cleaned = pd.concat([test_df, test_ohe_df, test_ohe_df2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bdeedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "train_df_cleaned['discount'] = train_df_cleaned.apply(lambda x: int(x['discount_amount'] > 0), axis = 1)\n",
    "train_df_cleaned['late'] = train_df_cleaned.apply(lambda x: int(x['late_fee'] > 0), axis = 1)\n",
    "test_df_cleaned['discount'] = test_df_cleaned.apply(lambda x: int(x['discount_amount'] > 0), axis = 1)\n",
    "test_df_cleaned['late'] = test_df_cleaned.apply(lambda x: int(x['late_fee'] > 0), axis = 1)   \n",
    "train_df_cleaned = train_df_cleaned.drop(['agency_name', 'state', 'late_fee', 'discount_amount'], axis = 1)\n",
    "test_df_cleaned = test_df_cleaned.drop(['agency_name', 'state', 'late_fee', 'discount_amount'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f683173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, test\n",
    "y = train_df_cleaned['compliance']\n",
    "X = train_df_cleaned.drop(['compliance'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run logistic regression and make predictions\n",
    "gbc = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\n",
    "gbc_train = gbc.predict_proba(X_train)\n",
    "gbc_test = gbc.predict_proba(X_test)   \n",
    "\n",
    "#train_fpr, train_tpr, _ = metrics.roc_curve(y_train.reshape(-1, 1), gbc_train[:, 1])\n",
    "#test_fpr, test_tpr, _ = metrics.roc_curve(y_test.reshape(-1, 1), gbc_test[:, 1])\n",
    "#train_score, test_score = metrics.auc(train_fpr, train_tpr), metrics.auc(test_fpr, test_tpr)\n",
    "\n",
    "# Generate predictions\n",
    "gbc_result = gbc.predict_proba(test_df_cleaned)[:, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
